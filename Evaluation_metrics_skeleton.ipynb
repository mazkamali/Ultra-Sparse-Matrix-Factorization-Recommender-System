{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d4d0d7",
   "metadata": {},
   "source": [
    "### install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0288e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a0b7b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import TESTCode_generate_csr\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import copy\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297feee7",
   "metadata": {},
   "source": [
    "### generate random sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "18f20f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a random sparse matrix as the full_sample_matrix\n",
    "rnd_useit = TESTCode_generate_csr.RandomUserItemMatrix(num_items=1000, num_users=100000, density=0.05)\n",
    "mat_y = rnd_useit.generateMatrix()          # this is the full sample matrix\n",
    "y_df = rnd_useit.getMatinPandasFormat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "538f3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a random sparse matrix as predictions_matrix based on full_sample_matrix\n",
    "\n",
    "mat_pred = copy.deepcopy(mat_y)\n",
    "# Get non-zero indices\n",
    "rows, cols = mat_pred.nonzero()\n",
    "non_zero_indices = list(zip(rows, cols))\n",
    "\n",
    "# Randomly select 40% of nonzero indices\n",
    "selected_indices = np.random.choice(len(non_zero_indices), size=int(0.4*mat_pred.nnz), replace=False)\n",
    "\n",
    "# Set selected entries to zero\n",
    "for idx in selected_indices:\n",
    "    r, c = non_zero_indices[idx]\n",
    "    mat_pred[r, c] = 0\n",
    "\n",
    "# Eliminate explicit zeros to keep CSR structure clean\n",
    "mat_pred.eliminate_zeros()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ff7135b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a random sparse matrix as training_matrix based on full_sample_matrix (this matrix has to be less dense than prediction_matrix)\n",
    "\n",
    "mat_train = copy.deepcopy(mat_y)\n",
    "# Get non-zero indices\n",
    "rows, cols = mat_train.nonzero()\n",
    "non_zero_indices = list(zip(rows, cols))\n",
    "\n",
    "# Randomly select 60% of nonzero indices\n",
    "selected_indices = np.random.choice(len(non_zero_indices), size=int(0.6*mat_train.nnz), replace=False)\n",
    "\n",
    "# Set selected entries to zero\n",
    "for idx in selected_indices:\n",
    "    r, c = non_zero_indices[idx]\n",
    "    mat_train[r, c] = 0\n",
    "\n",
    "# Eliminate explicit zeros to keep CSR structure clean\n",
    "mat_train.eliminate_zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d885ebb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4877074, 2926245, 1950830)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_y.nnz, mat_pred.nnz, mat_train.nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "919d030a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 1000), (100000, 1000))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_y.shape, mat_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e40421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat_y_df = rnd_useit.getMatinPandasFormat()\n",
    "# mat_pred_df = pd.DataFrame.sparse.from_spmatrix(mat_pred)\n",
    "# mat_train_df = pd.DataFrame.sparse.from_spmatrix(mat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69869284",
   "metadata": {},
   "source": [
    "### evaluation class and its methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c87e94c-d023-4a9f-8f8b-a38e74e1d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class RecSysEvaluator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''\n",
    "        initialize the RecSysEvaluator with whatever other vals you feel are appropriate\n",
    "        Each class must have a dict to track RMSE, Precision@K, etc\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "\n",
    "        '''\n",
    "        self.evaluation_scores = {} #create dictionary to track scores\n",
    "        \n",
    "        \n",
    "        \n",
    "    def calc_rmse(self, actual_matrix: csr_matrix, predictions_matrix: csr_matrix, training_matrix: csr_matrix) :\n",
    "        '''\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        actual_matrix : csr_matrix (Sparse Scipy matrix)\n",
    "            The ground truth matrix with all the actual ratings by the users we are analyzing. \n",
    "            Only use the random seed of the sample matrix, not the full massive ratings table.\n",
    "            \n",
    "        predictions_matrix : csr_matrix (Sparse Scipy matrix)\n",
    "            The matrix that has been trained and is making predictions on ratings by users.\n",
    "            This matrix can be the Simple Recommender, the Vanilla Matrix Factorization Model,\n",
    "            or the Hybrid Matrix Factorization model. The RMSE calculations and processes should be the \n",
    "            same for all 3\n",
    "            \n",
    "        training_matrix: csr_matrix (Sparse Scipy matrix)\n",
    "            The matrix that the model has been training on. Use this matrix to make sure you are excluding\n",
    "            ratings that ALREADY existed prior to the recommender systems ratings. You can create a boolean mask\n",
    "            or you can simply exclude any ratings already listed in this matrix so that only the new predicted\n",
    "            ratings are being evaluated\n",
    "            \n",
    "            \n",
    "        Edge Case to consider. What if the user made 0 new ratings in the test set? How do you calc RMSE?\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Nothing. Update the dictionary value for the RMSE ex: self.evaluation_scores['RMSE'] = average_rmse_score \n",
    "\n",
    "        when doing rmse, you are porbably going to do full matrix - training matrix, \n",
    "        that in theory should give you testing matrix, \n",
    "        now that you have the testing samples you should do test rating value - predicted rating value, \n",
    "        to get how far away we are from the true data\n",
    "\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "        # calculate test_matrix\n",
    "        test_matrix = actual_matrix - training_matrix\n",
    "\n",
    "        # calculate the difference matrix between predictions and training\n",
    "        pred_matrix = abs(predictions_matrix - training_matrix)\n",
    "\n",
    "        # Compute difference\n",
    "        diff = test_matrix - pred_matrix\n",
    "\n",
    "        # Compute squared error only on non-zero entries\n",
    "        squared_error = diff.multiply(diff)  \n",
    "\n",
    "        # Sum of squared errors\n",
    "        sum_squared_error = squared_error.sum()\n",
    "\n",
    "        # Number of elements (total, not just non-zero)\n",
    "        n_elements = diff.nnz\n",
    "\n",
    "        # RMSE\n",
    "        rmse = np.sqrt(sum_squared_error / n_elements)\n",
    "\n",
    "        # add to RMSE dict\n",
    "        self.evaluation_scores[\"RMSE\"] = rmse\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    def calc_mae(self, actual_matrix: csr_matrix, predictions_matrix: csr_matrix, training_matrix: csr_matrix): \n",
    "        '''\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        Calculate the MAE as well just so that we can switch between the two if we need to.\n",
    "        Process will be exactly the same as the RMSE calculation\n",
    "        \n",
    "        actual_matrix : csr_matrix (Sparse Scipy matrix)\n",
    "            The ground truth matrix with all the actual ratings by the users we are analyzing. \n",
    "            Only use the random seed of the sample matrix, not the full massive ratings table.\n",
    "            \n",
    "        predictions_matrix : csr_matrix (Sparse Scipy matrix)\n",
    "            The matrix that has been trained and is making predictions on ratings by users.\n",
    "            This matrix can be the Simple Recommender, the Vanilla Matrix Factorization Model,\n",
    "            or the Hybrid Matrix Factorization model. The RMSE calculations and processes should be the \n",
    "            same for all 3\n",
    "            \n",
    "        training_matrix: csr_matrix (Sparse Scipy matrix)\n",
    "            The matrix that the model has been training on. Use this matrix to make sure you are excluding\n",
    "            ratings that ALREADY existed prior to the recommender systems ratings. You can create a boolean mask\n",
    "            or you can simply exclude any ratings already listed in this matrix so that only the new predicted\n",
    "            ratings are being evaluated\n",
    "            \n",
    "            \n",
    "        Edge Case to consider. What if the user made 0 new ratings in the test set? How do you calc RMSE?\n",
    "        Returns\n",
    "        -------\n",
    "        Nothing. Update the dictionary value for the MAE\n",
    "\n",
    "        '''\n",
    "\n",
    "        # calculate test_matrix\n",
    "        test_matrix = actual_matrix - training_matrix\n",
    "\n",
    "        # calculate the difference matrix between predictions and training\n",
    "        pred_matrix = abs(predictions_matrix - training_matrix)\n",
    "\n",
    "        \n",
    "        # Compute difference\n",
    "        diff = abs(test_matrix - pred_matrix)\n",
    "\n",
    "        # Sum of absolute errors\n",
    "        sum_abs_error = diff.sum()\n",
    "\n",
    "        # Number of elements (total, not just non-zero)\n",
    "        n_elements = diff.nnz\n",
    "\n",
    "        # MAE\n",
    "        mae = sum_abs_error / n_elements\n",
    "        \n",
    "        # add to MAE dict\n",
    "        self.evaluation_scores[\"MAE\"] = mae\n",
    "\n",
    "        \n",
    "    def calc_precision_recall_at_k(self, actual_matrix: csr_matrix, predictions_matrix: csr_matrix,training_matrix: csr_matrix, k, user_count, threshold = 3.5 ) :\n",
    "        '''\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        actual_matrix : csr_matrix (Sparse Scipy matrix)\n",
    "            The ground truth matrix with all the actual ratings by the users we are analyzing. \n",
    "            Only use the random seed of the sample matrix, not the full massive ratings table.\n",
    "            \n",
    "        predictions_matrix : csr_matrix (Sparse Scipy matrix)\n",
    "            The matrix that has been trained and is making predictions on ratings by users.\n",
    "            This matrix can be the Simple Recommender, the Vanilla Matrix Factorization Model,\n",
    "            or the Hybrid Matrix Factorization model. The RMSE calculations and processes should be the \n",
    "            same for all 3\n",
    "        training_matrix: csr_matrix (Sparse Scipy matrix)\n",
    "            The matrix that the model has been training on. Use this matrix to make sure you are excluding\n",
    "            ratings that ALREADY existed prior to the recommender systems ratings. You can create a boolean mask\n",
    "            or you can simply exclude any ratings already listed in this matrix so that only the new predicted\n",
    "            ratings are being evaluated\n",
    "            \n",
    "        k : integer\n",
    "            number of movies that the trained recommender will output\n",
    "        user_count: integer\n",
    "            number of total users that this recommender is making a movie recommendation for\n",
    "\n",
    "        Edge Case to consider. What if the user made 0 new ratings in the test set? How do you calc RMSE?\n",
    "        Returns\n",
    "        -------\n",
    "        Nothing. Update the dictionary value for the Precision@K\n",
    "\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        You will need to calculate the number of \"relevant items\". Relevant Items are the total number\n",
    "        of movies that the user Actually rated in the test set. Exclude any of that users ratings in the \n",
    "        training set. If the recommender recommends 3 movies and only 1 out of those 3 recommended \n",
    "        movies was actually rated (is in the relevant items set) then Precision@K is 1/3=.333 \n",
    "        \n",
    "        Formula is Precision@K = (Number of relevant items in the top K recommendations)/ K\n",
    "        \n",
    "        You will also need to take the average Precision@K for all the users so that the final\n",
    "        Precision@K score is the sum of all the Precision@K scores for ALL the users Divided by\n",
    "        the total number of users\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        n_users = user_count   # user_count can be removed as an input and test_matrix.shape[0] can be used to compute n_users\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "\n",
    "        # calculate test_matrix\n",
    "        test_matrix = actual_matrix - training_matrix\n",
    "\n",
    "        # calculate the difference matrix between predictions and training\n",
    "        pred_matrix = abs(predictions_matrix - training_matrix)\n",
    "\n",
    "        for user in range(n_users):\n",
    "            # Get row slices for user\n",
    "            test_row = test_matrix[user].toarray().ravel()\n",
    "            pred_row = pred_matrix[user].toarray().ravel()\n",
    "\n",
    "            # Relevant items in test (non-zero ratings)\n",
    "            relevant_items = np.where(test_row > threshold)[0]\n",
    "\n",
    "            if len(relevant_items) == 0:\n",
    "                continue  # skip users with no relevant items\n",
    "\n",
    "            # Top-K predicted items\n",
    "            top_k_items = np.argsort(-pred_row)[:k]  # sort descending by prediction\n",
    "\n",
    "            # Intersection of recommended and relevant\n",
    "            recommended_relevant = np.intersect1d(top_k_items, relevant_items)\n",
    "\n",
    "            # Precision@K\n",
    "            precision = len(recommended_relevant) / k\n",
    "            # Recall@K\n",
    "            recall = len(recommended_relevant) / len(relevant_items)\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "\n",
    "        # Average across users\n",
    "        avg_precision = np.mean(precisions) if precisions else 0.0\n",
    "        avg_recall = np.mean(recalls) if recalls else 0.0\n",
    "\n",
    "        self.evaluation_scores[\"Precision@K\"] = avg_precision\n",
    "        self.evaluation_scores[\"Recall@K\"] = avg_recall\n",
    "\n",
    "\n",
    "        \n",
    "    def calc_recall_at_k(self, actual_matrix: csr_matrix, predictions_matrix: csr_matrix,training_matrix: csr_matrix, k, user_count ) :\n",
    "        '''\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        actual_matrix : csr_matrix (Sparse Scipy matrix)\n",
    "            The ground truth matrix with all the actual ratings by the users we are analyzing. \n",
    "            Only use the random seed of the sample matrix, not the full massive ratings table.\n",
    "            \n",
    "        predictions_matrix : csr_matrix (Sparse Scipy matrix)\n",
    "            The matrix that has been trained and is making predictions on ratings by users.\n",
    "            This matrix can be the Simple Recommender, the Vanilla Matrix Factorization Model,\n",
    "            or the Hybrid Matrix Factorization model. The RMSE calculations and processes should be the \n",
    "            same for all 3\n",
    "        training_matrix: csr_matrix (Sparse Scipy matrix)\n",
    "            The matrix that the model has been training on. Use this matrix to make sure you are excluding\n",
    "            ratings that ALREADY existed prior to the recommender systems ratings. You can create a boolean mask\n",
    "            or you can simply exclude any ratings already listed in this matrix so that only the new predicted\n",
    "            ratings are being evaluated\n",
    "            \n",
    "        k : integer\n",
    "            number of movies that the trained recommender will output\n",
    "            \n",
    "        user_count: integer\n",
    "            number of total users that this recommender is making a movie recommendation for\n",
    "        \n",
    "        Edge Case to consider. What if the user made 0 new ratings in the test set? How do you calc RMSE?\n",
    "        Returns\n",
    "        -------\n",
    "        Nothing. Update the dictionary value for the Precision@K\n",
    "\n",
    "        '''\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "        You will need to calculate the Total number of \"relevant items\". Relevant items are the total number of movies in the \n",
    "        test group that the user actually rated. If the recommender recommends 5 movies and only 1 of those 5 movies are \n",
    "        in that list of all new movies that the user rated in the test set (let's say the user rated 10 new movies in the test\n",
    "        set), then the Recall would be 1/10 = .1\n",
    "        \n",
    "        formula for Recall@K = (Number of relevant items in the top K recommendations)/(Total number of relevant items)\n",
    "        \n",
    "        You will also need to take the average Recall@K for all the users so that the final\n",
    "        Recall@K score is the sum of all the Recall@K scores for ALL the users Divided by\n",
    "        the total number of users\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    Stretch goal: calculate the NDCG@K. Lookup NDCG@K formula online to see how it is calculated\n",
    "    '''    \n",
    "    def calc_NDCG_at_k(self, actual_matrix: csr_matrix, predictions_matrix: csr_matrix,training_matrix: csr_matrix, k, user_count):\n",
    "        '''\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        actual_matrix : csr_matrix (Sparse Scipy matrix)\n",
    "            The ground truth matrix with all the actual ratings by the users we are analyzing. \n",
    "            Only use the random seed of the sample matrix, not the full massive ratings table.\n",
    "            \n",
    "        predictions_matrix : csr_matrix (Sparse Scipy matrix)\n",
    "            The matrix that has been trained and is making predictions on ratings by users.\n",
    "            This matrix can be the Simple Recommender, the Vanilla Matrix Factorization Model,\n",
    "            or the Hybrid Matrix Factorization model. The RMSE calculations and processes should be the \n",
    "            same for all 3\n",
    "            \n",
    "        training_matrix: csr_matrix (Sparse Scipy matrix)\n",
    "            The matrix that the model has been training on. Use this matrix to make sure you are excluding\n",
    "            ratings that ALREADY existed prior to the recommender systems ratings. You can create a boolean mask\n",
    "            or you can simply exclude any ratings already listed in this matrix so that only the new predicted\n",
    "            ratings are being evaluated\n",
    "            \n",
    "        k : TYPE\n",
    "            DESCRIPTION.\n",
    "        user_count : TYPE\n",
    "            DESCRIPTION.\n",
    "        \n",
    "        Edge Case to consider. What if the user made 0 new ratings in the test set? How do you calc RMSE?\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "\n",
    "        '''\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031f7ccb",
   "metadata": {},
   "source": [
    "### TEST EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dc242077",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = RecSysEvaluator()\n",
    "eval.calc_rmse(mat_y, mat_pred, mat_train)\n",
    "eval.calc_mae(mat_y, mat_pred, mat_train)\n",
    "eval.calc_precision_recall_at_k(mat_y, mat_pred, mat_train, 10, 100000, threshold=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d52b35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(3.4239408488101444), np.float64(3.0735169509987803))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.evaluation_scores[\"RMSE\"], eval.evaluation_scores[\"MAE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9ee80843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.619888), np.float64(0.5288648883752431))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.evaluation_scores[\"Precision@K\"], eval.evaluation_scores[\"Recalln@K\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b0a238",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
